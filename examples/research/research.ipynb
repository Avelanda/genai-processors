{
  "cells": [
    {
      "metadata": {
        "id": "2hIRfgOxHP4S"
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2025 DeepMind Technologies Limited. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "N6L5WnciBEMN"
      },
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-deepmind/genai-processors/blob/main/examples/research/research.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "zzFUsTefL_JV"
      },
      "cell_type": "markdown",
      "source": [
        "# Genai Processors Research Agent üß†\n",
        "\n",
        "This notebook provides:\n",
        "\n",
        "*   Setup instructions (including API key).\n",
        "*   Step-by-step execution of individual processors (`TopicGenerator`, `TopicResearcher`, `TopicVerbalizer`).\n",
        "*   Demonstration of chaining processors.\n",
        "*   Running the complete `ResearchAgent`.\n",
        "*   An advanced example applying the research agent to inform multimodal image generation."
      ]
    },
    {
      "metadata": {
        "id": "oxForuGtLv4L"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. üõ†Ô∏è Setup"
      ]
    },
    {
      "metadata": {
        "id": "1rvYAw1FmSMe"
      },
      "cell_type": "code",
      "source": [
        "!pip install genai_processors"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "WW1ZPsjynO39"
      },
      "cell_type": "markdown",
      "source": [
        "### API Key\n",
        "\n",
        "To use the GenAI model processors, you will need an API key. If you have not\n",
        "done so already, obtain your API key from Google AI Studio, and import it as a\n",
        "secret in Colab (recommended) or directly set it below."
      ]
    },
    {
      "metadata": {
        "id": "y3xZ8voInRmZ"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "u7arK-sNjEoy"
      },
      "cell_type": "code",
      "source": [
        "# @title Import modules\n",
        "from typing import AsyncIterable\n",
        "\n",
        "from genai_processors import content_api\n",
        "from genai_processors import processor\n",
        "from genai_processors import streams\n",
        "from genai_processors.core import genai_model\n",
        "from genai_processors.core import preamble\n",
        "from genai_processors.examples import research\n",
        "from google.genai import types as genai_types\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "ProcessorPart = processor.ProcessorPart\n",
        "\n",
        "\n",
        "def render_part(part: ProcessorPart) -\u003e None:\n",
        "  if part.substream_name == 'status':\n",
        "    display(Markdown(f'--- \\n *Status*: {part.text}'))\n",
        "  else:\n",
        "    try:\n",
        "      display(Markdown(part.text))\n",
        "    except Exception:\n",
        "      display(Markdown(f' {part.text} '))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "DOETzhfmdeRF"
      },
      "cell_type": "code",
      "source": [
        "# @title Prompt\n",
        "# @markdown Enter the prompt that will be used in the example\n",
        "USER_PROMPT = \"Research the best things about owning dalmatians!\"  # @param { \"type\": \"string\" }"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "O2lFQNicp5GN"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. üèó Processors\n",
        "\n",
        "The `ResearchAgent` is built on top of the Genai Processor library, leveraging its concurrency, chaining operations, and foundational tools for handling different data formats."
      ]
    },
    {
      "metadata": {
        "id": "a26q71K4p5GN"
      },
      "cell_type": "markdown",
      "source": [
        "### `TopicGenerator`\n",
        "\n",
        "The `TopicGenerator` processor generates a list of research topics based on the user's input content."
      ]
    },
    {
      "metadata": {
        "id": "e5EEV7ifp5GN"
      },
      "cell_type": "code",
      "source": [
        "p_generator = research.TopicGenerator(api_key=API_KEY)\n",
        "\n",
        "topic_parts = []\n",
        "input_stream = streams.stream_content([ProcessorPart(USER_PROMPT)])\n",
        "async for content_part in p_generator(input_stream):\n",
        "  if content_part.mimetype == 'application/json; type=Topic':\n",
        "    topic_parts.append(content_part)\n",
        "  else:\n",
        "    render_part(content_part)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "RnNvXq_Wp5GN"
      },
      "cell_type": "markdown",
      "source": [
        "### `TopicResearcher`\n",
        "\n",
        "The `TopicResearcher` processor researches specific `Topic` objects (produced by the `TopicGenerator`) and returns `ProcessorPart` objects containing `TopicResearch` in JSON format."
      ]
    },
    {
      "metadata": {
        "id": "3AhRin40okoP"
      },
      "cell_type": "code",
      "source": [
        "p_researcher = research.TopicResearcher(api_key=API_KEY)\n",
        "\n",
        "input_stream = streams.stream_content(topic_parts)\n",
        "topic_research_parts = []\n",
        "async for content_part in p_researcher.to_processor()(input_stream):\n",
        "  if content_part.mimetype == 'application/json; type=Topic':\n",
        "    topic_research_parts.append(content_part)\n",
        "  else:\n",
        "    render_part(content_part)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "lMOF2pEGokoP"
      },
      "cell_type": "markdown",
      "source": [
        "### `TopicVerbalizer`\n",
        "\n",
        "The `TopicVerbalizer` processor converts `TopicResearch` parts into human-readable research text."
      ]
    },
    {
      "metadata": {
        "id": "GenLofsKokoP"
      },
      "cell_type": "code",
      "source": [
        "p_verbalizer = research.TopicVerbalizer()\n",
        "\n",
        "input_stream = streams.stream_content(topic_research_parts)\n",
        "topic_verbalizer_parts = []\n",
        "async for content_part in p_verbalizer.to_processor()(input_stream):\n",
        "  render_part(content_part)\n",
        "  topic_verbalizer_parts.append(content_part)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "uGndUn57qpyB"
      },
      "cell_type": "markdown",
      "source": [
        "### Chaining the `TopicGenerator` and `TopicResearcher`\n",
        "\n",
        "\n",
        "We can chain our processors together to seamlessly generate `Topic` objects for futher processing."
      ]
    },
    {
      "metadata": {
        "id": "h9K5baOqqpyB"
      },
      "cell_type": "code",
      "source": [
        "topics = []\n",
        "\n",
        "pipeline = p_generator + p_researcher\n",
        "\n",
        "input_stream = streams.stream_content([ProcessorPart(USER_PROMPT)])\n",
        "async for content_part in pipeline(input_stream):\n",
        "  if content_part.mimetype == 'application/json; type=Topic':\n",
        "    topics.append(content_part.get_dataclass(research.interfaces.Topic))\n",
        "  else:\n",
        "    render_part(content_part)\n",
        "\n",
        "print(f'Researched {len(topics)} topics!')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "CwEsE-sDqpyB"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. ü§ñ Agent\n",
        "\n",
        "Now that we have all our building blocks, we can chain them together within our agent, resulting in a seamless flow of content."
      ]
    },
    {
      "metadata": {
        "id": "p9PgMpG5qpyB"
      },
      "cell_type": "code",
      "source": [
        "input_stream = streams.stream_content([ProcessorPart(USER_PROMPT)])\n",
        "\n",
        "output_parts = []\n",
        "async for content_part in research.ResearchAgent(api_key=API_KEY)(input_stream):\n",
        "  if content_part.substream_name != 'status':\n",
        "    output_parts.append(content_part)\n",
        "  render_part(content_part)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "awz2c2LhqpyB"
      },
      "cell_type": "code",
      "source": [
        "render_part(ProcessorPart(f\"\"\"# Final synthesized research\n",
        "\n",
        "{content_api.as_text(output_parts)}\"\"\"))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cTW-Erw4qpyB"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. üñºÔ∏è Multimodal Agent Example\n",
        "\n",
        "We can use reuse our research agent in different contexts.\n",
        "\n",
        "For this example, imagine we are creating an image and want to ensure it is realistic. We can use core processors and our research agent to provide the image generator with useful tips."
      ]
    },
    {
      "metadata": {
        "id": "NUGMenu8deRG"
      },
      "cell_type": "code",
      "source": [
        "class ResearchedImageGenerator(processor.PartProcessor):\n",
        "\n",
        "  def __init__(self, research_agent: research.ResearchAgent):\n",
        "    research_suffix = preamble.Suffix(\n",
        "        content=[\n",
        "            ProcessorPart(\n",
        "                'Please tailor your research so it can be used to provide an'\n",
        "                \" accurate image based on the user's content\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    self._research_pipeline = research_suffix + research_agent\n",
        "    self._img_gen_model = genai_model.GenaiModel(\n",
        "        api_key=API_KEY,\n",
        "        model_name='gemini-2.0-flash-exp-image-generation',\n",
        "        generate_content_config=genai_types.GenerateContentConfig(\n",
        "            response_modalities=['Text', 'Image']\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  async def call(\n",
        "      self, content_part: content_api.ProcessorPart\n",
        "  ) -\u003e AsyncIterable[content_api.ProcessorPart]:\n",
        "    if not content_api.is_text(content_part.mimetype):\n",
        "      raise ValueError('ResearchedImageGenerator expects text content')\n",
        "      return\n",
        "\n",
        "    user_prompt = content_part.text\n",
        "    research_content = []\n",
        "\n",
        "    research_input_stream = streams.stream_content([ProcessorPart(user_prompt)])\n",
        "\n",
        "    async for research_part in self._research_pipeline(research_input_stream):\n",
        "      yield research_part\n",
        "      research_content.append(research_part)\n",
        "\n",
        "    yield processor.status('Creating image...')\n",
        "    img_gen_content = [\n",
        "        ProcessorPart(\n",
        "            \"You are an expert at creating images based on a user's prompt and\"\n",
        "            ' using research provided to you'\n",
        "        ),\n",
        "        ProcessorPart(f'User prompt: {user_prompt}'),\n",
        "        ProcessorPart(f'Research: {content_api.as_text(research_content)}'),\n",
        "        ProcessorPart(\n",
        "            f'Produce a high quality image, as well as an explanation of how'\n",
        "            f' you used the research to inform your image.'\n",
        "        ),\n",
        "        ProcessorPart(f'Your image: '),\n",
        "    ]\n",
        "\n",
        "    img_gen_stream = processor.stream_content(img_gen_content)\n",
        "    async for img_gen_part in self._img_gen_model(img_gen_stream):\n",
        "      if content_api.is_image(img_gen_part.mimetype):\n",
        "        yield processor.status('Generated image using research!')\n",
        "      yield img_gen_part\n",
        "    yield processor.status('Done!')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "YmclTcR9deRG"
      },
      "cell_type": "code",
      "source": [
        "image_generator = ResearchedImageGenerator(\n",
        "    research.ResearchAgent(api_key=API_KEY)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "gottyQz-deRG"
      },
      "cell_type": "code",
      "source": [
        "user_prompt = 'Create an image of two dalmatians, one with brown spots \u0026 one with black spots, frolicking in Crystal Palace park.'  # @param { \"type\": \"string\" }"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "aXHr-hE9deRG"
      },
      "cell_type": "code",
      "source": [
        "img_gen_results = []\n",
        "\n",
        "async for content_part in image_generator(ProcessorPart(user_prompt)):\n",
        "  if content_api.is_text(content_part.mimetype):\n",
        "    render_part(content_part)\n",
        "  elif content_part.pil_image:\n",
        "    display(content_part.pil_image)\n",
        "    img_gen_results.append(content_part)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1TR6JIxtY9TPU5EBn12Uy5DqB6lRov3rL",
          "timestamp": 1741296571652
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
