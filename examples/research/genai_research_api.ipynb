{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzFUsTefL_JV"
      },
      "source": [
        "# Genai Research API üìñ\n",
        "\n",
        "*Powered by Genai Processors*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxForuGtLv4L"
      },
      "source": [
        "## Setup üç≥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7arK-sNjEoy"
      },
      "outputs": [],
      "source": [
        "from typing import AsyncIterable\n",
        "\n",
        "from genai_processors import content_api\n",
        "from genai_processors import processor\n",
        "from genai_processors import utils\n",
        "from genai_processors.core import genai_model\n",
        "from genai_processors.core import preamble\n",
        "from genai_processors.examples import research\n",
        "from google.genai import types as genai_types\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "ProcessorPart = processor.ProcessorPart\n",
        "\n",
        "\n",
        "def render_part(part: ProcessorPart) -\u003e None:\n",
        "  if part.substream_name == 'status':\n",
        "    display(Markdown(f'--- \\n *Status*: {part.text}'))\n",
        "  else:\n",
        "    try:\n",
        "      display(Markdown(part.text))\n",
        "    except Exception:\n",
        "      display(Markdown(f' {part.text} '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08ULZirydeRF"
      },
      "outputs": [],
      "source": [
        "API_KEY = 'your-api-key'  # @param { \"type\": \"string\" }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOETzhfmdeRF"
      },
      "outputs": [],
      "source": [
        "USER_PROMPT = \"Research the best things about owning dalmatians!\"  # @param { \"type\": \"string\" }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdMvGFufdeRF"
      },
      "source": [
        "## Processors üèó\n",
        "\n",
        "The `ResearchAgent` is powered by Genai `processors`, which provides a framework for building agents \u0026 pipelines that process a variety of content!\n",
        "\n",
        "It includes features for concurrency, chaining operations, and foundational tools for handling different data formats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCYJp7H1deRF"
      },
      "source": [
        "### `TopicGenerator` ‚úç\n",
        "\n",
        "The `TopicGenerator` processor generates a list of research topics, given the user's content!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuHD-6_OdeRF"
      },
      "outputs": [],
      "source": [
        "p_generator = research.TopicGenerator(api_key=API_KEY)\n",
        "\n",
        "topic_parts = []\n",
        "input_stream = utils.stream_content([ProcessorPart(USER_PROMPT)])\n",
        "async for content_part in p_generator(input_stream):\n",
        "  if content_part.mimetype == 'application/json; type=Topic':\n",
        "    topic_parts.append(content_part)\n",
        "  else:\n",
        "    render_part(content_part)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URX-_mhEdeRF"
      },
      "source": [
        "### `TopicResearcher` üîç\n",
        "\n",
        "The `TopicResearcher` processor researches specific `Topics`, which are produced by the TopicGenerator, and returns `ProcessParts` with `TopicResearch` JSON!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_ikrebJdeRF"
      },
      "outputs": [],
      "source": [
        "p_researcher = research.TopicResearcher(api_key=API_KEY)\n",
        "\n",
        "input_stream = utils.stream_content(topic_parts)\n",
        "topic_research_parts = []\n",
        "async for content_part in p_researcher.to_processor()(input_stream):\n",
        "  if content_part.mimetype == 'application/json; type=Topic':\n",
        "    topic_research_parts.append(content_part)\n",
        "  else:\n",
        "    render_part(content_part)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wgln4W4deRF"
      },
      "source": [
        "### `TopicVerbalizer` üîç\n",
        "\n",
        "The `TopicVerbalizer` processor converts `TopicResearch` parts into human-readable research text!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfzbDm9deRF"
      },
      "outputs": [],
      "source": [
        "p_verbalizer = research.TopicVerbalizer()\n",
        "\n",
        "input_stream = utils.stream_content(topic_research_parts)\n",
        "topic_verbalizer_parts = []\n",
        "async for content_part in p_verbalizer.to_processor()(input_stream):\n",
        "  render_part(content_part)\n",
        "  topic_verbalizer_parts.append(content_part)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSKIdaZxdeRF"
      },
      "source": [
        "### Chaining the `TopicGenerator` \u0026 `TopicResearcher` ‚õì\n",
        "\n",
        "\n",
        "We can chain our processors together, to seamlessly generated `Topic` objects for post-processing!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08mSMNordeRF"
      },
      "outputs": [],
      "source": [
        "topics = []\n",
        "\n",
        "pipeline = p_generator + p_researcher\n",
        "\n",
        "input_stream = utils.stream_content([ProcessorPart(USER_PROMPT)])\n",
        "async for content_part in pipeline(input_stream):\n",
        "  if content_part.mimetype == 'application/json; type=Topic':\n",
        "    topics.append(content_part.get_dataclass(research.interfaces.Topic))\n",
        "  else:\n",
        "    render_part(content_part)\n",
        "\n",
        "print(f'Researched {len(topics)} topics!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4-z5E6HdeRG"
      },
      "source": [
        "## Agent ü§ñ\n",
        "\n",
        "Now we have all our building blocks, we can chain these together inside our agent, resulting in a seamless flow of Content!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn7grwqCdeRG"
      },
      "outputs": [],
      "source": [
        "input_stream = utils.stream_content([ProcessorPart(USER_PROMPT)])\n",
        "\n",
        "output_parts = []\n",
        "async for content_part in research.ResearchAgent(api_key=API_KEY)(input_stream):\n",
        "  if content_part.substream_name != 'status':\n",
        "    output_parts.append(content_part)\n",
        "  render_part(content_part)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llvLKrMTdeRG"
      },
      "outputs": [],
      "source": [
        "render_part(ProcessorPart(f\"\"\"# Final synthesized research\n",
        "\n",
        "{content_api.as_text(output_parts)}\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Q5phFHdeRG"
      },
      "source": [
        "## Multimodal Agent Example üì∏\n",
        "\n",
        "We can use re-use our research agent in different contexts!\n",
        "\n",
        "For this example, imagine we are creating an image \u0026 want to ensure it is realistic... we can make use of core Processors \u0026 our research agent to provide the image generator with a bunch of useful tips!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUGMenu8deRG"
      },
      "outputs": [],
      "source": [
        "class ResearchedImageGenerator(processor.PartProcessor):\n",
        "\n",
        "  def __init__(self, research_agent: research.ResearchAgent):\n",
        "    research_suffix = preamble.Suffix(\n",
        "        content=[\n",
        "            ProcessorPart(\n",
        "                'Please tailor your research so it can be used to provide an'\n",
        "                \" accurate image based on the user's content\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    self._research_pipeline = research_suffix + research_agent\n",
        "    self._img_gen_model = genai_model.GenaiModel(\n",
        "        api_key=API_KEY,\n",
        "        model_name='gemini-2.0-flash-exp-image-generation',\n",
        "        generate_content_config=genai_types.GenerateContentConfig(\n",
        "            response_modalities=['Text', 'Image']\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  async def __call__(\n",
        "      self, content_part: content_api.ProcessorPart\n",
        "  ) -\u003e AsyncIterable[content_api.ProcessorPart]:\n",
        "    if not content_api.is_text(content_part.mimetype):\n",
        "      raise ValueError('ResearchedImageGenerator expects text content')\n",
        "      return\n",
        "\n",
        "    user_prompt = content_part.text\n",
        "    research_content = []\n",
        "\n",
        "    research_input_stream = utils.stream_content([ProcessorPart(user_prompt)])\n",
        "\n",
        "    async for research_part in self._research_pipeline(research_input_stream):\n",
        "      yield research_part\n",
        "      research_content.append(research_part)\n",
        "\n",
        "    yield processor.status('Creating image...')\n",
        "    img_gen_content = [\n",
        "        ProcessorPart(\n",
        "            \"You are an expert at creating images based on a user's prompt and\"\n",
        "            ' using research provided to you'\n",
        "        ),\n",
        "        ProcessorPart(f'User prompt: {user_prompt}'),\n",
        "        ProcessorPart(f'Research: {content_api.as_text(research_content)}'),\n",
        "        ProcessorPart(\n",
        "            f'Produce a high quality image, as well as an explanation of how'\n",
        "            f' you used the research to inform your image.'\n",
        "        ),\n",
        "        ProcessorPart(f'Your image: '),\n",
        "    ]\n",
        "\n",
        "    img_gen_stream = processor.stream_content(img_gen_content)\n",
        "    async for img_gen_part in self._img_gen_model(img_gen_stream):\n",
        "      if content_api.is_image(img_gen_part.mimetype):\n",
        "        yield processor.status('Generated image using research!')\n",
        "      yield img_gen_part\n",
        "    yield processor.status('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmclTcR9deRG"
      },
      "outputs": [],
      "source": [
        "image_generator = ResearchedImageGenerator(\n",
        "    research.ResearchAgent(api_key=API_KEY)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gottyQz-deRG"
      },
      "outputs": [],
      "source": [
        "user_prompt = 'Create an image of two dalmatians, one with brown spots \u0026 one with black spots, frolicking in Crystal Palace park.'  # @param { \"type\": \"string\" }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXHr-hE9deRG"
      },
      "outputs": [],
      "source": [
        "img_gen_results = []\n",
        "\n",
        "async for content_part in image_generator(ProcessorPart(user_prompt)):\n",
        "  if content_api.is_text(content_part.mimetype):\n",
        "    render_part(content_part)\n",
        "  elif content_part.pil_image:\n",
        "    display(content_part.pil_image)\n",
        "    img_gen_results.append(content_part)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1TR6JIxtY9TPU5EBn12Uy5DqB6lRov3rL",
          "timestamp": 1741296571652
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
